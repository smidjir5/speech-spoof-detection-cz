<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Speech spoof detection Czech</title>
</head>
<body>
    <style>
        table {
          border:1px solid black;
        }
        th,td {
            padding: 3px;
            text-align: center;
        }
    </style>
    <a href="https://fel.cvut.cz/en/research-groups/speech-processing-laboratory/about-group" target="_blank"><img src="speech_lab.png" alt="img speech_lab" height="50" style="float: right;"></a>
    <h2>Speech spoof (deepfake) detection for Czech language</h2>
    <p>This is an overview of the progress of diploma thesis aimed at developing a tool for detecting spoofed speech in Czech.</p>
    <p>
        <b>Author:</b> Bc. Jiří Šmíd, Faculty of Elecrical Engineering, Czech Technical University in Prague, smidjir5@fel.cvut.cz
    </p>
    <p>
        <b>Thesis supervisor:</b> Doc. Ing. Petr Pollák, CSc. Faculty of Elecrical Engineering, Czech Technical University in Prague, <a href="https://noel.feld.cvut.cz/~pollak/" target="_blank">webpage</a>
    </p>

    <p>
        With the advancement of machine learning and artificial intelligence tools, there has also been significant progress in text-to-speech (TTS)
        and voice conversion (VC) technologies, which can replicate a target voice. These technologies are often exploited—frequently in combination with 
        deepfake videos—for various fraudulent activities targeting businesses, politicians and ordinary individuals.
        The aim of this thesis is to evaluate the capability of a model trained on English or Chinese—languages for which datasets containing both 
        genuine and spoofed speech are available—and to develop the first, or one of the first, tools for detecting such machine-generated speech in the Czech language.
    </p>
    <p>
        In order to develop and train such a tool and to evaluate models trained in English, it is first necessary to create a dataset 
        containing both natural and spoofed Czech speech. <b>More details can be found <a href="dataset.html">here</a>. </b>
    </p>
    <p>
        Examples of fraud involving speech spoofing and deepfakes can be found <a href="fraud.html">here</a>
    </p>
    <b>Webpage work in progress</b><br>
    <i>FPRs, FNRs and EERs shown below are ratios, not percentages. Need to be edited. </i>
    <hr>
    <h2>Webpage sections</h2>
    <a href="dataset.html"><li>SP Spoof CS dataset</li></a> <br>
    <a href="fraud.html"><li>Fraud exaples</li></a>
    <hr>
    
    <h2>Spoof detection</h2>
    <p>This section describes </p>
    <hr>
    <h3>One class classification</h3>
    <p>The One-Class Softmax (OC-Softmax) loss function enhances spoofing detection in automatic speaker verification (ASV) systems by compacting bona fide speech 
        embeddings while pushing spoofed speech representations away. Instead of treating spoofed and bona fide samples as separate classes, OC-Softmax defines a 
        hypersphere centered around bona fide embeddings and enforces a margin to separate them from outliers. During training, a cosine-based decision boundary ensures that 
        bona fide speech remains within a constrained region, while spoofed speech is pushed beyond a threshold margin. The network structure consists of a CNN-based feature 
        extractor, followed by an embedding layer, where OC-Softmax optimizes the distance between bona fide and spoofed embeddings. A radius-based decision function determines 
        whether an input belongs to the bona fide class, enabling the model to detect previously unseen spoofing attacks without requiring spoofed training data. This approach 
        improves generalization, robustness, and security in ASV systems. [Automaticaly compiled from <a href="https://arxiv.org/pdf/2010.13995" target="_blank">Arxiv</a>]</p>
    <p>
    <p>


        There are two possible approaches for classification with this model:
        Binary Classification – This approach utilizes the last layer with two neurons, applying softmax or argmax for decision-making. Not recommended when using OC Softmax, as this layer is not utilized during the training stage.
        Recommended when using the traditional approach with Cross-Entropy loss.
        One-Class Loss – This method leverages the penultimate fully connected layer, where a one-class loss function is used during training to 
        compute a score. Based on the evaluation dataset (or any other relevant criteria), a classification threshold can be determined. Additionally, it is 
        possible to estimate probabilities or confidence scores for classification decisions.
    </p>
        Metrics computed from last classification layer: 
        <li>False positive and negative rate (FPR, FNR)</li>
        <li>Equal error rate (EER)</li>
    </p>
    <p>
        Metrics calculated from OC softmax score:
        <li>Treshold for score so FPR and FNR are equal and equal to ideal EER (also computed) [taken from ASV Spoof Challenge]</li>
        <li>FPR, FNR and EER for binary classification based on one class score and treshhold computed during developing stage.</li>
    </p>
    <h3>One class classification - Experiment 1</h3>
    <p>
        The goal of the first experiment was to evaluate the model's ability to generalize to a different language dataset than the one it was trained on.
        The dataset described above was used with a pretrained network from the ASVspoof 2019 dataset, employing a one-class loss function. 
        The entire SP Spoof CS dataset was utilized for this evaluation.
    
    <h4>Overall results</h4>
    <table>
   <!--model1028-->
        
        <tr><th>Treshold ideal</th> <td>-0.94</td></tr>
        <tr><th>EER ideal</th><td>0.41</td></tr>
        <tr><td>---</td></tr>
        <tr><th>Treshold from dev</th><td>--</td></tr>
        
        <tr><th>EER</th><td>--</td></tr>
        <tr><th>FPR</th><td>--</td></tr>
        <tr><th>FNR</th><td>--</td></tr>
        
    </table>
    <h4>TTS/VC tools results</h4>
    <table>
        <tr><th>Tool</th><th>EER ideal*</th><th>ER**</th></tr>
        <tr><th>Bonafide</th><td>0.208</td><td>--</td></tr>
        <tr><th>XTTS</th><td>0.210</td><td>--</td></tr>
        <tr><th>FVC</th><td>0.000</td><td>--</td></tr>
        <tr><th>kNN VC</th><td>0.347</td><td>--</td></tr>
        <tr><th>Seed VC</th><td>0.268</td><td>--</td></tr>
        <tr><th>Diff-Hier VC</th><td>0.125</td><td>--</td></tr>
    </table>
    <p>
        *  threshold computed from test dataset, so FPR and FNR would be same <br>
        ** Error rate - FPR for bonafide, FNR for spoof. Treshhold computed from development dataset - more realistic for usage
    </p>    

    </p>
    <h3>One class classification - Experiment 2</h3>
    The goal of this experiment was to conduct a limited fine-tuning of the network and train OC Softmax on the SP Spoof CS dataset. The objective was to familiarize the system with a 
    different language, dataset, speakers, and VC/TTS tools, as the results from Experiment 1 were unsatisfactory. The dataset was randomly shuffled and divided into train, development, and test subsets following a 60% : 10% : 30% ratio.
    OC Softmax parameters were kept at defaut values: r_real = 0.9, r_fake = 0.5, alpha=20. 
    System was finetuded for 2 epochs with learning rate 0.000003. For simplicity, the data was classified into two groups—bona fide and spoof—based on the computed score. The classification threshold was determined during the development stage.
    </p>
    <h4>Overall results</h4>
    <table>

        
        <tr><th>Treshold ideal</th> <td>0.406</td></tr>
        <tr><th>EER ideal</th><td>0.0089</td></tr>
        <tr><td>---</td></tr>
        <tr><th>Treshold from dev</th><td>0.776</td></tr>
        
        <tr><th>EER</th><td>0.015</td></tr>
        <tr><th>FPR</th><td>0.029</td></tr>
        <tr><th>FNR</th><td>0.001</td></tr>
        
    </table>
    <h4>TTS/VC tools results</h4>
    <table>
        <tr><th>Tool</th><th>EER ideal*</th><th>ER**</th></tr>
        <tr><th>Bonafide</th><td>0.005</td><td>0.029</td></tr>
        <tr><th>XTTS</th><td>0.002</td><td>0.001</td></tr>
        <tr><th>FVC</th><td>0.009</td><td>0.001</td></tr>
        <tr><th>kNN VC</th><td>0.006</td><td>0.001</td></tr>
        <tr><th>Seed VC</th><td>0.009</td><td>0.001</td></tr>
        <tr><th>Diff-Hier VC</th><td>0.000</td><td>0.000</td></tr>
    </table>
    <p>
        *  threshold computed from test dataset, so FPR and FNR would be same <br>
        ** Error rate - FPR for bonafide, FNR for spoof. Treshhold computed from development dataset - more realistic for usage
    </p>
    <p>
        This experiment demonstrates that the model's structure is capable of rapid fine-tuning, requiring only two epochs to achieve promising results. The evaluation was conducted on a randomly split dataset, where all types of 
        attacks and all source datasets were included across the train, development, and test subsets. So for the seen attacks it provides promising results.
    </p>
    <h3>One class classification - Experiment 3</h3>
    <p>
        The goal of this experiment was to modify the previous setup by introducing an unseen attack (a new TTS/VC tool) into the test dataset. 
        To achieve this, utterances generated by Seed VC were included only in the test set. The remaining utterances were randomly split using the same ratio as in the previous experiment 
        (60% train, 10% dev, 30% test).
    </p>
    <h4>Overall results</h4>
    <table>

        
        <tr><th>Treshold ideal</th> <td>0.934</td></tr>
        <tr><th>EER ideal</th><td>0.116</td></tr>
        <tr><td>---</td></tr>
        <tr><th>Treshold from dev</th><td>0.509</td></tr>
        
        <tr><th>EER</th><td>0.143</td></tr>
        <tr><th>FPR</th><td>0.011</td></tr>
        <tr><th>FNR</th><td>0.275</td></tr>
        
    </table>
    <h4>TTS/VC tools results</h4>
    <table>
        <tr><th>Tool</th><th>EER ideal*</th><th>ER**</th></tr>
        <tr><th>Bonafide</th><td>0.058</td><td>0.011</td></tr>
        <tr><th>XTTS</th><td>0.0</td><td>0.010</td></tr>
        <tr><th>FVC</th><td>0.0</td><td>0.017</td></tr>
        <tr><th>kNN VC</th><td>0.0</td><td>0.007</td></tr>
        <tr><th>Seed VC</th><td>0.161</td><td style="color: red;">0.75</td></tr>
        <tr><th>Diff-Hier VC</th><td>0.0</td><td>0.000</td></tr>
    </table>
    <p>
        *  threshold computed from test dataset, so FPR and FNR would be same <br>
        ** Error rate - FPR for bonafide, FNR for spoof. Treshhold computed from development dataset - more realistic for usage
    </p>
    <p>
        These results indicate overfitting to known types of attack. After only two epochs with a very low learning rate, the model is able to classify known attacks, but its performance on unseen attacks is significantly worse.
        This issue is evident in the histograms below, where the OC scores of the unseen attack (Seed VC) overlap with the bona fide scores, highlighting the model's inability to distinguish between them effectively.
    </p>

    <img src="oc_seed_test.png" width="80%">
    <br>
    <h3>One class class Classification - Experiment 4</h3>
    <p>
        In this experiment One-class loss function was enhanced. The proposed loss function introduces an uncertainty-aware penalty for speech spoof detection by applying a softplus-based 
        regularization to output scores within a predefined margin around the decision boundary. Specifically, predictions that fall between the thresholds r_fake-margin and r_real+margin
        are penalized using a scaled softplus function, encouraging the model to make more confident predictions. Outside this uncertain region, no additional loss is applied. This approach enhances decision boundary sharpness while maintaining gradient stability, leading to improved robustness against ambiguous spoofed speech samples.
    </p>

    <h4>Overall results</h4>
    <table>

        
        <tr><th>Treshold ideal</th> <td>0.288</td></tr>
        <tr><th>EER ideal</th><td>0.065</td></tr>
        <tr><td>---</td></tr>
        <tr><th>Treshold from dev</th><td>0.197</td></tr>
        
        <tr><th>EER</th><td>0.136</td></tr>
        <tr><th>FPR</th><td>0.005</td></tr>
        <tr><th>FNR</th><td>0.268</td></tr>
        
    </table>
    <h4>TTS/VC tools results</h4>
    <table>
        <tr><th>Tool</th><th>EER ideal*</th><th>ER**</th></tr>
        <tr><th>Bonafide</th><td>0.032</td><td>0.005</td></tr>
        <tr><th>XTTS</th><td>0.0</td><td>0.0007</td></tr>
        <tr><th>FVC</th><td>0.0</td><td>0.013</td></tr>
        <tr><th>kNN VC</th><td>0.0</td><td>0.003</td></tr>
        <tr><th>Seed VC</th><td><b>0.09</b></td><td style="color: red;">0.740</td></tr>
        <tr><th>Diff-Hier VC</th><td>0.0</td><td>0.001</td></tr>
    </table>
    <p>
        *  threshold computed from test dataset, so FPR and FNR would be same <br>
        ** Error rate - FPR for bonafide, FNR for spoof. Treshhold computed from development dataset - more realistic for usage
    </p>

    <p>
        The results demonstrate promising performance when using a threshold calculated from the test data (ideal case). 
        With a properly chosen threshold, this method reduces the Equal Error Rate (EER) by half.

        Interestingly, for spoofed scores, the score histograms remain relatively narrow, whereas for bona fide scores, the histograms broaden significantly. This suggests that the applied method affects 
        genuine speech more than spoofed speech, leading to greater score variability in bona fide samples.

    Additionally, it appears that determining the threshold from the development dataset by balancing the False Positive Rate (FPR) and False Negative Rate (FNR) may not 
    be sufficient for optimal performance.
    </p>

        <tr><td><img src="oc_seed_test_botside_margin_0.3.png" width="80%"></td></tr>

        <h4>Promising solution: </h4>
        <p>
            Even though bona fide scores do not follow a normal distribution, it appears effective to set the classification threshold as: mean(bonafide_scores) - k*std(bonafide_scores) 
            calculated from the development dataset.
            Adjusting k allows for fine-tuning the classification balance based on the desired objective—a more balanced classification or a higher False Positive Rate (FPR) for increased security. 
            Below are the results for k = 1.
        </p>
        <h4>Overall results</h4>
        <!--models_seed_test_enhanced_oc-->
        <table>
    
            
            <tr><th>Treshold ideal</th> <td>0.288</td></tr>
            <tr><th>EER ideal</th><td>0.065</td></tr>
            <tr><td>---</td></tr>
            <tr><th>Treshold from dev</th><td>0.364</td></tr>
            
            <tr><th>EER</th><td>0.096</td></tr>
            <tr><th>FPR</th><td>0.180</td></tr>
            <tr><th>FNR</th><td>0.014</td></tr>
            
        </table>
        <h4>TTS/VC tools results</h4>
        <table>
            <tr><th>Tool</th><th>EER ideal*</th><th>ER**</th></tr>
            <tr><th>Bonafide</th><td>0.032</td><td style="color: red;">0.18</td></tr>
            <tr><th>XTTS</th><td>0.0</td><td>0.000</td></tr>
            <tr><th>FVC</th><td>0.0</td><td>0.000</td></tr>
            <tr><th>kNN VC</th><td>0.0</td><td>0.000</td></tr>
            <tr><th>Seed VC</th><td>0.09</td><td><b>0.039</b></td></tr>
            <tr><th>Diff-Hier VC</th><td>0.0</td><td>0.000</td></tr>
        </table>
        <p>
            *  threshold computed from test dataset, so FPR and FNR would be same <br>
            ** Error rate - FPR for bonafide, FNR for spoof. Treshhold computed from development dataset - more realistic for usage
        </p>




        <h3>One class classification - Experiment 5</h3>
        
        <p>
            This experiment aimed to verify whether the results from Experiment 4 were not coincidental. To test this, utterances generated by XTTS (Attack 1) and FVC (Attack 2) were included 
            only in the test dataset, while the remaining data were divided according to the same ratio as in previous experiments. The proposed enhanced OC Softmax method was applied, along 
            with the mean-std threshold calculation approach. 
        </p>
        <h4>Overall results</h4>
        <!--models_seed_test_enhanced_oc_4-->
        
        <table>
    
            
            <tr><th>Treshold ideal</th> <td>0.249</td></tr>
            <tr><th>EER ideal</th><td>0.004</td></tr>
            <tr><td>---</td></tr>
            <tr><th></th><th>k = 1</th><th>k = 2</th></tr>
            <tr><th>Treshold from dev</th><td>0.461</td><td>0.34</td></tr>
            
            <tr><th>EER</th><td>0.081</td><td>0.019</td></tr>
            <tr><th>FPR</th><td>0.162</td><td>0.039</td></tr>
            <tr><th>FNR</th><td>0.00007</td><td>0.0004</td></tr>
            
        </table>
        <h4>TTS/VC tools results</h4>
        <table>
            <tr><th></th><th></th><th>k = 1</th><th> k = 2</th></tr>
            <tr><th>Tool</th><th>EER ideal*</th><th>ER**</th><th>ER**</th></tr>
            <tr><th>Bonafide</th><td>0.002</td><td>0.162</td><td>0.038</td></tr>
            <tr><th>XTTS</th><td>0.003</td><td><b>0.0002</b></td><td>0.0001</td></tr>
            <tr><th>FVC</th><td>0.002</td><td><b>0.000</b></td><td>0.000</td></tr>
            <tr><th>kNN VC</th><td>0.000</td><td>0.000</td><td>0.000</td></tr>
            <tr><th>Seed VC</th><td>0.002</td><td>0.000</td><td>0.001</td></tr>
            <tr><th>Diff-Hier VC</th><td>0.0</td><td>0.000</td><td>0.000</td></tr>
        </table>
        <p>
            *  threshold computed from test dataset, so FPR and FNR would be same <br>
            ** Error rate - FPR for bonafide, FNR for spoof. Treshhold computed from development dataset - more realistic for usage
        </p>
        <p>
            As evidenced by the tables, the proposed method improves the classification of unseen attacks. Additionally, better score separation is observable in the histograms 
            below, indicating enhanced discrimination between bona fide and spoofed utterances. 
        </p>
        <img src="oc_xtts_fvc_test_botside_margin_0.3.png" width="80%">
</body>
</html>